{
  "task_description": "# Pipeline D: Training Data Implementation\n\nComplete the training data pipeline to transform Parquet event data into RL-ready training batches. This enables machine learning models to train on historical trading data with proper observation/action/reward structures.\n\n## Rationale\nCore blocker for RL model training - users cannot train bots without a working data pipeline. This directly addresses the pain point of 'Difficulty collecting high-quality training data for RL models'.\n\n## User Stories\n- As an ML researcher, I want to load captured trading sessions as training data so that I can train RL models on historical patterns\n- As a data scientist, I want consistent feature extraction so that model training is reproducible\n\n## Acceptance Criteria\n- [ ] Observation schema extracts 36 features from Parquet events\n- [ ] Transitions (obs, action, reward, next_obs, done) are correctly generated\n- [ ] Batch loader provides training-ready data to RL frameworks\n- [ ] Integration tests verify pipeline with real captured data\n- [ ] Documentation explains feature engineering choices\n",
  "workflow_type": "feature"
}